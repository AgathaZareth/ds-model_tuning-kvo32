{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Objectives\" data-toc-modified-id=\"Objectives-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Objectives</a></span></li><li><span><a href=\"#Model-Tuning\" data-toc-modified-id=\"Model-Tuning-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Model Tuning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Hyperparameters\" data-toc-modified-id=\"Hyperparameters-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Hyperparameters</a></span><ul class=\"toc-item\"><li><span><a href=\"#Difference-from-Parametric-/-Non-Parametric-Models\" data-toc-modified-id=\"Difference-from-Parametric-/-Non-Parametric-Models-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Difference from Parametric / Non-Parametric Models</a></span></li></ul></li><li><span><a href=\"#Trying-Different-Values\" data-toc-modified-id=\"Trying-Different-Values-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Trying Different Values</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-Prep\" data-toc-modified-id=\"Data-Prep-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Data Prep</a></span></li><li><span><a href=\"#Preparing-the-Test-Set\" data-toc-modified-id=\"Preparing-the-Test-Set-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>Preparing the Test Set</a></span></li><li><span><a href=\"#$k$-Nearest-Neighbors-Model\" data-toc-modified-id=\"$k$-Nearest-Neighbors-Model-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>$k$-Nearest Neighbors Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Decreasing-$k$\" data-toc-modified-id=\"Decreasing-$k$-2.2.3.1\"><span class=\"toc-item-num\">2.2.3.1&nbsp;&nbsp;</span>Decreasing $k$</a></span></li></ul></li><li><span><a href=\"#Decision-Tree\" data-toc-modified-id=\"Decision-Tree-2.2.4\"><span class=\"toc-item-num\">2.2.4&nbsp;&nbsp;</span>Decision Tree</a></span><ul class=\"toc-item\"><li><span><a href=\"#Changing-the-branching-criterion\" data-toc-modified-id=\"Changing-the-branching-criterion-2.2.4.1\"><span class=\"toc-item-num\">2.2.4.1&nbsp;&nbsp;</span>Changing the branching criterion</a></span></li></ul></li></ul></li><li><span><a href=\"#Gridsearching\" data-toc-modified-id=\"Gridsearching-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Gridsearching</a></span><ul class=\"toc-item\"><li><span><a href=\"#GridSearchCV\" data-toc-modified-id=\"GridSearchCV-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span><code>GridSearchCV</code></a></span></li><li><span><a href=\"#Choice-of-Grid-Values\" data-toc-modified-id=\"Choice-of-Grid-Values-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Choice of Grid Values</a></span></li></ul></li><li><span><a href=\"#Exercise\" data-toc-modified-id=\"Exercise-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Exercise</a></span></li><li><span><a href=\"#GridSearching-a-Pipeline\" data-toc-modified-id=\"GridSearching-a-Pipeline-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>GridSearching a Pipeline</a></span></li><li><span><a href=\"#Random-Searching\" data-toc-modified-id=\"Random-Searching-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Random Searching</a></span><ul class=\"toc-item\"><li><span><a href=\"#RandomizedSearchCV-with-LogisticRegression\" data-toc-modified-id=\"RandomizedSearchCV-with-LogisticRegression-2.6.1\"><span class=\"toc-item-num\">2.6.1&nbsp;&nbsp;</span><code>RandomizedSearchCV</code> with <code>LogisticRegression</code></a></span></li></ul></li><li><span><a href=\"#Exercise\" data-toc-modified-id=\"Exercise-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>Exercise</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats as stats\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,\\\n",
    "cross_val_score, RandomizedSearchCV\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "SWBAT:\n",
    "\n",
    "- Explain what hyperparameters are\n",
    "- Describe the purpose of gridsearching\n",
    "- Implement gridsearching for the purposes of model optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Many of the models we have looked at are really *families* of models in the sense that they make use of **hyperparameters**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Thus for example the $k$-nearest-neighbors algorithm allows us to make:\n",
    "\n",
    "- a 1-nearest-neighbor model;\n",
    "- a 2-nearest-neighbors model;\n",
    "- a 3-nearest-neighbors model;\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Or, for another example, the decision tree algorithm allows us to make:\n",
    "\n",
    "- a classifier that branches according to information gain;\n",
    "- a classifier that branches according to Gini impurity;\n",
    "- a regressor that branches according to mean squared error;\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Depending on the sort of problem and data at hand, it is natural to experiment with different values of these hyperparameters to try to improve model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Difference from Parametric / Non-Parametric Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Contrast the notion of hyperparameters with the distinction between parametric and non-parametric models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A linear regression model is parametric in the sense that we start with a given model *form* and we then search for the optimal parameters to fill in that form. But *those* parameters are not the sort we might tweak for the purposes of improving model performance. On the contrary, there is one best set of parameters, and the training of the model is a matter of finding those optimal values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Trying Different Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "penguins = sns.load_dataset('penguins')\n",
    "\n",
    "penguins.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "penguins.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We'll try to predict species given the other columns' values. Let's dummy-out `island` and `sex`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "penguins.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "penguins = penguins.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y = penguins.pop('species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    penguins, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train_cat = X_train.select_dtypes('object')\n",
    "\n",
    "ohe = OneHotEncoder(\n",
    "    drop='first',\n",
    "    sparse=False)\n",
    "\n",
    "dums = ohe.fit_transform(X_train_cat)\n",
    "dums_df = pd.DataFrame(dums,\n",
    "                       columns=ohe.get_feature_names(),\n",
    "                       index=X_train_cat.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train_nums = X_train.select_dtypes('float64')\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "ss.fit(X_train_nums)\n",
    "nums_df = pd.DataFrame(ss.transform(X_train_nums),\n",
    "                      index=X_train_nums.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_clean = pd.concat([nums_df, dums_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "knn_model.fit(X_train_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(estimator=knn_model, X=X_train_clean,\n",
    "               y=y_train, cv=10)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.median(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Preparing the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_test_cat = X_test.select_dtypes('object')\n",
    "\n",
    "test_dums = ohe.transform(X_test_cat)\n",
    "test_dums_df = pd.DataFrame(test_dums,\n",
    "                       columns=ohe.get_feature_names(),\n",
    "                      index=X_test_cat.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_test_nums = X_test.select_dtypes('float64')\n",
    "\n",
    "test_nums = ss.transform(X_test_nums)\n",
    "test_nums_df = pd.DataFrame(test_nums,\n",
    "                           index=X_test_nums.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_test_clean = pd.concat([test_nums_df,\n",
    "                 test_dums_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_test_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### $k$-Nearest Neighbors Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "knn_model.score(X_test_clean, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Decreasing $k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "knn5 = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "knn5.fit(X_train_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "knn5.score(X_test_clean, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ct = DecisionTreeClassifier(random_state=10)\n",
    "\n",
    "ct.fit(X_train_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ct.score(X_test_clean, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Changing the branching criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ct = DecisionTreeClassifier(criterion='entropy',\n",
    "                          random_state=10)\n",
    "\n",
    "ct.fit(X_train_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ct.score(X_test_clean, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Gridsearching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It's not a bad idea to experiment with the values of your models' hyperparameters a bit as you're getting a feel for your models' performance. But there are more systematic ways of going about the search for optimal hyperparameters. One method of hyperparameter tuning is **gridsearching**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The idea is to build multiple models with different hyperparameter values and then see which one performs the best. The hyperparameters and the values to try form a sort of *grid* along which we are looking for the best performance. For example:\n",
    "\n",
    "\n",
    "    1           | 'minkowski' | 'uniform'\n",
    "    3           | 'manhattan' | 'distance'\n",
    "    5           |\n",
    "    ______________________________________\n",
    "    n_neighbors | metric      | weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Scikit-Learn has a `GridSearchCV` class whose `fit()` method runs this procedure. Note that this can be quite computationally expensive since:\n",
    "\n",
    "- A model is constructed for each combination of hyperparameter values that we input; and\n",
    "- Each model is cross-validated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### `GridSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "\n",
    "grid = {\n",
    "    'n_neighbors': [1, 3, 5],\n",
    "    'metric': ['minkowski', 'manhattan'],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Question: How many models will we be constructing with this grid?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Initialize the gridsearch object with five-fold cross-validation\n",
    "\n",
    "gs = GridSearchCV(estimator=knn_model, param_grid=grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gs.fit(X_train_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gs.best_estimator_.score(X_test_clean, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gs.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Choice of Grid Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Which values should you pick for your grid? Intuitively, you should try both \"large\" and \"small\" values, but of course what counts as large and small will really depend on the type of hyperparameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- For a $k$-nearest neighbors model, 1 or 3 would be a small value for the number of neighbors and 15 or 17 would be a large value.\n",
    "- For a decision tree model, what counts as a small `max_depth` will really depend on the size of your training data. A `max_depth` of 5 would likely have little effect on a very small dataset but, at the same time, it would probably significantly decrease the variance of a model where the dataset is large.\n",
    "- For a logistic regression's regularization constant, you may want to try a set of values that are exponentially separated, like \\[1, 10, 100, 1000\\].\n",
    "- **If a gridsearch finds optimal values at the ends of your hyperparameter ranges, you might try another gridsearch with more extreme values.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Do a GridSearch on a **decision tree model** of penguin species. What are the optimal values for the hyperparameters you've chosen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## GridSearching a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ss_pipe = Pipeline(steps=[\n",
    "    ('ss', StandardScaler())\n",
    "])\n",
    "                \n",
    "ohe_pipe = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder(drop='first',\n",
    "                         sparse=False))\n",
    "])\n",
    "\n",
    "trans = ColumnTransformer(transformers=[\n",
    "    ('ss', ss_pipe, X_train_nums.columns),\n",
    "    ('ohe', ohe_pipe, X_train_cat.columns)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trans.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train_tr = trans.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_pipe = Pipeline(steps=[\n",
    "    ('trans', trans),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pipe_grid = {'knn__n_neighbors': [3, 5, 7], 'knn__p': [1, 2, 3]}\n",
    "\n",
    "gs_pipe = GridSearchCV(estimator=model_pipe, param_grid=pipe_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gs_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gs_pipe.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Random Searching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It is also possible to search for good hyperparameter values randomly. This is a nice choice if computation time is an issue or if you are tuning over continuous hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### `RandomizedSearchCV` with `LogisticRegression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_reg_grid = {'C': stats.uniform(loc=0, scale=10),\n",
    "               'l1_ratio': stats.expon(scale=0.2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rs = RandomizedSearchCV(estimator=LogisticRegression(penalty='elasticnet',\n",
    "                                                    solver='saga',\n",
    "                                                    max_iter=1000,\n",
    "                                                    random_state=42),\n",
    "                        param_distributions=log_reg_grid,\n",
    "                       random_state=42)\n",
    "\n",
    "rs.fit(X_train_clean, y_train)\n",
    "\n",
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Use a Random Forest Classifier to predict the category of price range for the phones in this dataset. Try tuning some hyperparameters using GridSearch, and then write up a short paragraph about your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "phones_train = pd.read_csv('data/train.csv')\n",
    "\n",
    "phones_test = pd.read_csv('data/test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "TOC",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "347px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
